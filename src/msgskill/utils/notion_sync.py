"""
NotionåŒæ­¥æ¨¡å— - å°†outputæ•°æ®åŒæ­¥åˆ°Notionæ•°æ®åº“

åŠŸèƒ½:
    - å°†ArticleItemæ•°æ®å†™å…¥Notionæ•°æ®åº“
    - æ”¯æŒæ‰¹é‡åŒæ­¥
    - æ”¯æŒå»é‡ï¼ˆåŸºäºsource_urlï¼‰
    - è‡ªåŠ¨åˆ›å»ºNotioné¡µé¢å±æ€§

ä½¿ç”¨å‰å‡†å¤‡:
    1. åœ¨Notionä¸­åˆ›å»ºé›†æˆï¼Œè·å–Integration Token
    2. åˆ›å»ºæ•°æ®åº“ï¼Œå¹¶è¿æ¥é›†æˆ
    3. åœ¨config/sources.jsonä¸­é…ç½®notion_syncé…ç½®é¡¹
"""

import json
from datetime import datetime
from pathlib import Path
from typing import Optional, List, Dict, Any
import httpx
from ..models import ArticleItem, FetchResult
from ..utils.logger import logger
from ..config import get_config


class NotionSync:
    """NotionåŒæ­¥å™¨ - å°†æ•°æ®åŒæ­¥åˆ°Notionæ•°æ®åº“"""
    
    def __init__(
        self,
        api_token: str,
        databases: Dict[str, str],
        enabled: bool = True
    ):
        """
        åˆå§‹åŒ–NotionåŒæ­¥å™¨
        
        Args:
            api_token: Notion Integration Token
            databases: æ•°æ®æºåˆ°æ•°æ®åº“IDçš„æ˜ å°„å­—å…¸ï¼Œæ ¼å¼: {"github": "database_id", "rss": "database_id", ...}
            enabled: æ˜¯å¦å¯ç”¨åŒæ­¥
        """
        self.api_token = api_token
        self.api_base_url = "https://api.notion.com/v1"
        self.enabled = enabled
        self.headers = {
            "Authorization": f"Bearer {api_token}",
            "Notion-Version": "2022-06-28",  # Notion APIç‰ˆæœ¬
            "Content-Type": "application/json"
        }
        
        # å¤„ç†æ•°æ®åº“æ˜ å°„ï¼Œæå–IDå¹¶è½¬æ¢ä¸ºUUIDæ ¼å¼
        self.databases = {}
        for source_type, db_id_or_url in databases.items():
            if db_id_or_url:
                self.databases[source_type] = self._extract_database_id(db_id_or_url)
        
        # å¦‚æœæ²¡æœ‰é…ç½®ç‰¹å®šæ•°æ®æºçš„æ•°æ®åº“ï¼Œä½¿ç”¨é»˜è®¤æ•°æ®åº“ï¼ˆgithubï¼‰
        self.default_database_id = self.databases.get("github")
    
    def get_database_id(self, source_type: str) -> Optional[str]:
        """
        æ ¹æ®æ•°æ®æºç±»å‹è·å–å¯¹åº”çš„æ•°æ®åº“ID
        
        Args:
            source_type: æ•°æ®æºç±»å‹ (github, rss, hackernews, arxiv)
            
        Returns:
            æ•°æ®åº“IDï¼Œå¦‚æœæœªé…ç½®åˆ™è¿”å›é»˜è®¤æ•°æ®åº“ID
        """
        # ä¼˜å…ˆä½¿ç”¨æŒ‡å®šæ•°æ®æºçš„æ•°æ®åº“
        database_id = self.databases.get(source_type)
        
        # å¦‚æœæœªé…ç½®ï¼Œä½¿ç”¨é»˜è®¤æ•°æ®åº“ï¼ˆgithubï¼‰
        if not database_id:
            database_id = self.default_database_id
        
        return database_id
    
    def _extract_database_id(self, database_id_or_url: str) -> str:
        """
        ä»URLæˆ–ç›´æ¥IDä¸­æå–æ•°æ®åº“ID
        
        Args:
            database_id_or_url: æ•°æ®åº“IDæˆ–å®Œæ•´URL
            
        Returns:
            æå–çš„æ•°æ®åº“IDï¼ˆ32ä½å­—ç¬¦ï¼‰
        """
        # å¦‚æœæ˜¯URLæ ¼å¼ï¼Œæå–ID
        if "notion.so" in database_id_or_url:
            # æå–URLä¸­çš„IDéƒ¨åˆ†
            # æ ¼å¼: https://www.notion.so/ID?v=...
            parts = database_id_or_url.split("/")
            for part in parts:
                if len(part) == 32 and part.isalnum():
                    return part
            # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•ä»æŸ¥è¯¢å‚æ•°å‰æå–
            if "?" in database_id_or_url:
                base = database_id_or_url.split("?")[0]
                id_part = base.split("/")[-1]
                if len(id_part) == 32:
                    return id_part
        
        # å¦‚æœå·²ç»æ˜¯IDæ ¼å¼ï¼Œè½¬æ¢ä¸ºUUIDæ ¼å¼ï¼ˆ8-4-4-4-12ï¼‰
        clean_id = database_id_or_url.replace("-", "").strip()
        if len(clean_id) == 32:
            # è½¬æ¢ä¸ºUUIDæ ¼å¼: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
            return f"{clean_id[:8]}-{clean_id[8:12]}-{clean_id[12:16]}-{clean_id[16:20]}-{clean_id[20:]}"
        
        # å¦‚æœéƒ½ä¸åŒ¹é…ï¼Œè¿”å›åŸå€¼ï¼ˆè®©APIè°ƒç”¨æ—¶æš´éœ²é”™è¯¯ï¼‰
        return database_id_or_url
    
    def _get_field_name(self, field_key: str, source_type: str) -> str:
        """
        æ ¹æ®æ•°æ®æºç±»å‹è·å–å­—æ®µåç§°ï¼ˆç»Ÿä¸€ä½¿ç”¨è‹±æ–‡å­—æ®µåï¼‰
        
        Args:
            field_key: å­—æ®µé”®å (title, source_url, summary, published_date)
            source_type: æ•°æ®æºç±»å‹
            
        Returns:
            å­—æ®µåç§°
        """
        # å­—æ®µåç§°æ˜ å°„ï¼ˆç»Ÿä¸€ä½¿ç”¨è‹±æ–‡ï¼‰
        field_mapping = {
            "title": "Title",
            "source_url": "Source URL",
            "summary": "Summary",
            "published_date": "Published Date"
        }
        
        return field_mapping.get(field_key, "")
    
    def _convert_article_to_notion_properties(self, item: ArticleItem) -> Dict[str, Any]:
        """
        å°†ArticleItemè½¬æ¢ä¸ºNotioné¡µé¢å±æ€§
        
        Notionæ•°æ®åº“å­—æ®µï¼ˆç»Ÿä¸€ä½¿ç”¨è‹±æ–‡ï¼‰:
        - Title (title): æ ‡é¢˜
        - Source URL (url): é“¾æ¥
        - Summary (rich_text): æ‘˜è¦
        - Published Date (date): å‘å¸ƒæ—¥æœŸ
        
        Args:
            item: ArticleItemå¯¹è±¡
            
        Returns:
            Notioné¡µé¢å±æ€§å­—å…¸
        """
        properties = {}
        
        # Title (å¿…éœ€å­—æ®µ)
        title_field = self._get_field_name("title", item.source_type)
        if title_field:
            properties[title_field] = {
                "title": [{"text": {"content": item.title}}]
            }
        
        # Summary
        if item.summary:
            summary_field = self._get_field_name("summary", item.source_type)
            if summary_field:
                properties[summary_field] = {
                    "rich_text": [{"text": {"content": item.summary}}]
                }
        
        # Source URL
        if item.source_url:
            url_field = self._get_field_name("source_url", item.source_type)
            if url_field:
                properties[url_field] = {
                    "url": item.source_url
                }
        
        # Published Date
        if item.published_date:
            try:
                from email.utils import parsedate_to_datetime
                from datetime import datetime
                
                date_str = item.published_date
                # å°è¯•è§£æRFC 2822æ ¼å¼ï¼ˆRSSå¸¸ç”¨æ ¼å¼ï¼‰
                if "," in date_str and len(date_str) > 20:
                    try:
                        dt = parsedate_to_datetime(date_str)
                        date_str = dt.strftime("%Y-%m-%d")
                    except:
                        # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•ISOæ ¼å¼
                        if "T" in date_str:
                            date_str = date_str.split("T")[0]
                        else:
                            date_str = date_str.split(" ")[0]
                elif "T" in date_str:
                    # ISOæ ¼å¼
                    date_str = date_str.split("T")[0]
                else:
                    # å…¶ä»–æ ¼å¼ï¼Œåªå–æ—¥æœŸéƒ¨åˆ†
                    date_str = date_str.split(" ")[0]
                
                # éªŒè¯æ—¥æœŸæ ¼å¼ï¼ˆYYYY-MM-DDï¼‰
                if len(date_str) >= 10 and date_str[4] == "-" and date_str[7] == "-":
                    date_field = self._get_field_name("published_date", item.source_type)
                    if date_field:
                        properties[date_field] = {
                            "date": {"start": date_str[:10]}
                        }
            except Exception:
                pass
        
        return properties
    
    def _check_page_exists(self, source_url: str, database_id: str, source_type: str) -> Optional[str]:
        """
        æ£€æŸ¥é¡µé¢æ˜¯å¦å·²å­˜åœ¨ï¼ˆåŸºäºSource URLå»é‡ï¼‰
        
        Args:
            source_url: æ¥æºURL
            database_id: æ•°æ®åº“ID
            source_type: æ•°æ®æºç±»å‹ï¼ˆç”¨äºè·å–æ­£ç¡®çš„å­—æ®µåï¼‰
            
        Returns:
            å¦‚æœå­˜åœ¨ï¼Œè¿”å›é¡µé¢IDï¼›å¦åˆ™è¿”å›None
        """
        try:
            # è·å–æ­£ç¡®çš„å­—æ®µåç§°
            url_field = self._get_field_name("source_url", source_type)
            if not url_field:
                return None
            
            response = httpx.post(
                f"{self.api_base_url}/databases/{database_id}/query",
                headers=self.headers,
                json={
                    "filter": {
                        "property": url_field,
                        "url": {
                            "equals": source_url
                        }
                    }
                },
                timeout=10.0
            )
            response.raise_for_status()
            results = response.json().get("results", [])
            if results:
                return results[0]["id"]
            return None
        except Exception as e:
            logger.debug(f"æ£€æŸ¥Notioné¡µé¢æ˜¯å¦å­˜åœ¨æ—¶å‡ºé”™: {e}")
            return None
    
    def sync_item(self, item: ArticleItem, skip_existing: bool = True) -> bool:
        """
        åŒæ­¥å•ä¸ªArticleItemåˆ°Notion
        
        Args:
            item: ArticleItemå¯¹è±¡
            skip_existing: å¦‚æœå·²å­˜åœ¨æ˜¯å¦è·³è¿‡
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        if not self.enabled:
            return False
        
        # æ ¹æ®æ•°æ®æºç±»å‹è·å–å¯¹åº”çš„æ•°æ®åº“ID
        database_id = self.get_database_id(item.source_type)
        if not database_id:
            logger.warning(f"âš ï¸ æœªé…ç½® {item.source_type} çš„æ•°æ®åº“IDï¼Œè·³è¿‡åŒæ­¥")
            return False
        
        try:
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            if skip_existing:
                existing_page_id = self._check_page_exists(item.source_url, database_id, item.source_type)
                if existing_page_id:
                    logger.debug(f"è·³è¿‡å·²å­˜åœ¨çš„Notioné¡µé¢: {item.title[:50]}")
                    return True
            
            # è½¬æ¢ä¸ºNotionå±æ€§
            properties = self._convert_article_to_notion_properties(item)
            
            # åˆ›å»ºé¡µé¢
            response = httpx.post(
                f"{self.api_base_url}/pages",
                headers=self.headers,
                json={
                    "parent": {"database_id": database_id},
                    "properties": properties
                },
                timeout=10.0
            )
            response.raise_for_status()
            
            logger.debug(f"âœ… å·²åŒæ­¥åˆ°Notion ({item.source_type}): {item.title[:50]}")
            return True
            
        except httpx.HTTPStatusError as e:
            logger.error(f"âŒ NotionåŒæ­¥å¤±è´¥ (HTTP {e.response.status_code}): {item.title[:50]} - {e.response.text[:200]}")
            return False
        except Exception as e:
            logger.error(f"âŒ NotionåŒæ­¥å¤±è´¥: {item.title[:50]} - {str(e)}")
            return False
    
    def sync_items(self, items: List[ArticleItem], skip_existing: bool = True) -> Dict[str, Any]:
        """
        æ‰¹é‡åŒæ­¥ArticleItemåˆ—è¡¨åˆ°Notion
        
        Args:
            items: ArticleItemåˆ—è¡¨
            skip_existing: å¦‚æœå·²å­˜åœ¨æ˜¯å¦è·³è¿‡
            
        Returns:
            åŒæ­¥ç»“æœç»Ÿè®¡
        """
        if not self.enabled:
            return {
                "success": False,
                "reason": "NotionåŒæ­¥æœªå¯ç”¨",
                "total": len(items),
                "synced": 0,
                "skipped": 0,
                "failed": 0
            }
        
        synced = 0
        skipped = 0
        failed = 0
        
        for item in items:
            # è·å–è¯¥æ•°æ®æºå¯¹åº”çš„æ•°æ®åº“ID
            database_id = self.get_database_id(item.source_type)
            if not database_id:
                failed += 1
                continue
            
            existing_page_id = None
            if skip_existing:
                existing_page_id = self._check_page_exists(item.source_url, database_id, item.source_type)
            
            if existing_page_id:
                skipped += 1
                continue
            
            if self.sync_item(item, skip_existing=False):
                synced += 1
            else:
                failed += 1
        
        return {
            "success": True,
            "total": len(items),
            "synced": synced,
            "skipped": skipped,
            "failed": failed
        }
    
    def sync_fetch_result(self, result: FetchResult, skip_existing: bool = True) -> Dict[str, Any]:
        """
        åŒæ­¥FetchResultåˆ°Notion
        
        Args:
            result: FetchResultå¯¹è±¡
            skip_existing: å¦‚æœå·²å­˜åœ¨æ˜¯å¦è·³è¿‡
            
        Returns:
            åŒæ­¥ç»“æœç»Ÿè®¡
        """
        return self.sync_items(result.items, skip_existing=skip_existing)
    
    def sync_json_file(self, json_file: Path, skip_existing: bool = True) -> Dict[str, Any]:
        """
        ä»JSONæ–‡ä»¶åŒæ­¥æ•°æ®åˆ°Notion
        
        Args:
            json_file: JSONæ–‡ä»¶è·¯å¾„
            skip_existing: å¦‚æœå·²å­˜åœ¨æ˜¯å¦è·³è¿‡
            
        Returns:
            åŒæ­¥ç»“æœç»Ÿè®¡
        """
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # å¤„ç†FetchResultæ ¼å¼ï¼ˆæ ‡å‡†æ ¼å¼ï¼ŒåŒ…å«itemsæ•°ç»„ï¼‰
            if isinstance(data, dict) and "items" in data:
                items = []
                for item_data in data.get("items", []):
                    try:
                        item = ArticleItem(**item_data)
                        items.append(item)
                    except Exception as e:
                        logger.warning(f"è·³è¿‡æ— æ•ˆçš„ArticleItem: {e}")
                        continue
                
                return self.sync_items(items, skip_existing=skip_existing)
            # å¤„ç†RSSæ ¼å¼ï¼ˆåŒ…å«feedsç»“æ„ï¼‰
            elif isinstance(data, dict) and "feeds" in data:
                items = []
                for feed_name, feed_data in data.get("feeds", {}).items():
                    if isinstance(feed_data, dict):
                        feed_items = feed_data.get("items", [])
                        for item_data in feed_items:
                            try:
                                # RSSæ ¼å¼è½¬æ¢ä¸ºArticleItem
                                item = ArticleItem(
                                    title=item_data.get("title", ""),
                                    summary=item_data.get("summary", "")[:300],
                                    source_url=item_data.get("link", ""),
                                    published_date=item_data.get("published"),
                                    source_type="rss",
                                    article_tag=item_data.get("article_tag", "AIèµ„è®¯"),
                                    author=item_data.get("author"),
                                    tags=item_data.get("tags", []),
                                    ai_score=item_data.get("ai_score")
                                )
                                items.append(item)
                            except Exception as e:
                                logger.warning(f"è·³è¿‡æ— æ•ˆçš„RSS item: {e}")
                                continue
                
                return self.sync_items(items, skip_existing=skip_existing)
            # å¤„ç†arXivæ ¼å¼ï¼ˆåŒ…å«papersæ•°ç»„ï¼‰
            elif isinstance(data, dict) and "papers" in data:
                items = []
                for paper in data.get("papers", []):
                    try:
                        # arXivè®ºæ–‡è½¬æ¢ä¸ºArticleItem
                        items.append(ArticleItem(
                            title=paper.get("title", ""),
                            summary=paper.get("summary", "")[:300],
                            source_url=paper.get("pdf_url") or paper.get("arxiv_url", ""),
                            published_date=paper.get("published"),
                            source_type="arxiv",
                            article_tag="AIè®ºæ–‡",
                            author=", ".join(paper.get("authors", [])),
                            tags=paper.get("categories", []),
                            ai_score=None
                        ))
                    except Exception as e:
                        logger.warning(f"è·³è¿‡æ— æ•ˆçš„arXivè®ºæ–‡: {e}")
                        continue
                return self.sync_items(items, skip_existing=skip_existing)
            else:
                return {
                    "success": False,
                    "reason": "ä¸æ”¯æŒçš„JSONæ ¼å¼ï¼ˆéœ€è¦åŒ…å«itemsæˆ–feedså­—æ®µï¼‰",
                    "total": 0,
                    "synced": 0,
                    "skipped": 0,
                    "failed": 0
                }
        except Exception as e:
            logger.error(f"è¯»å–JSONæ–‡ä»¶å¤±è´¥: {e}")
            return {
                "success": False,
                "reason": str(e),
                "total": 0,
                "synced": 0,
                "skipped": 0,
                "failed": 0
            }


def get_notion_sync() -> Optional[NotionSync]:
    """
    ä»é…ç½®è·å–NotionåŒæ­¥å™¨å®ä¾‹
    
    Returns:
        NotionSyncå®ä¾‹ï¼Œå¦‚æœæœªé…ç½®åˆ™è¿”å›None
    """
    try:
        config = get_config()
        notion_config = config.get_notion_config()
        
        if not notion_config or not notion_config.get("enabled"):
            return None
        
        api_token = notion_config.get("api_token")
        if not api_token:
            logger.warning("âš ï¸ Notion API Tokenæœªé…ç½®ï¼Œè·³è¿‡åŒæ­¥")
            return None
        
        # è·å–æ•°æ®åº“é…ç½®
        databases_config = notion_config.get("databases", {})
        databases = {}
        
        # æå–å„æ•°æ®æºçš„æ•°æ®åº“ID
        for source_type in ["github", "rss", "hackernews", "arxiv"]:
            db_config = databases_config.get(source_type, {})
            if isinstance(db_config, dict):
                db_id = db_config.get("database_id", "")
            else:
                # å…¼å®¹æ—§é…ç½®æ ¼å¼ï¼ˆç›´æ¥æ˜¯å­—ç¬¦ä¸²ï¼‰
                db_id = db_config if isinstance(db_config, str) else ""
            
            if db_id:
                databases[source_type] = db_id
        
        # å¦‚æœæ²¡æœ‰é…ç½®ä»»ä½•æ•°æ®åº“ï¼Œå°è¯•ä½¿ç”¨æ—§çš„database_idé…ç½®ï¼ˆå‘åå…¼å®¹ï¼‰
        if not databases and notion_config.get("database_id"):
            databases["github"] = notion_config.get("database_id")
            logger.info("ğŸ“ ä½¿ç”¨æ—§é…ç½®æ ¼å¼ï¼Œæ‰€æœ‰æ•°æ®æºå°†åŒæ­¥åˆ°GitHubæ•°æ®åº“")
        
        if not databases:
            logger.warning("âš ï¸ æœªé…ç½®ä»»ä½•Notionæ•°æ®åº“ï¼Œè·³è¿‡åŒæ­¥")
            return None
        
        return NotionSync(
            api_token=api_token,
            databases=databases,
            enabled=notion_config.get("enabled", True)
        )
    except Exception as e:
        logger.warning(f"âš ï¸ è·å–Notioné…ç½®å¤±è´¥: {e}")
        return None
