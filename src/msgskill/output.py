"""
è¾“å‡ºç®¡ç†æ¨¡å— - å¤„ç†JSONè¾“å‡ºåˆ°å›ºå®šç›®å½•ç»“æ„ï¼Œæ”¯æŒå¢é‡äº§å‡º
"""

import json
from pathlib import Path
from datetime import datetime
from typing import Optional, Union
from .models import FetchResult, SearchResult


# é»˜è®¤è¾“å‡ºç›®å½•ç»“æ„
DEFAULT_OUTPUT_DIR = Path("output")
OUTPUT_STRUCTURE = {
    "base": DEFAULT_OUTPUT_DIR,
    "daily": DEFAULT_OUTPUT_DIR / "daily"  # æŒ‰æ—¥æœŸç»„ç»‡
}


class OutputManager:
    """è¾“å‡ºç®¡ç†å™¨ - ç®¡ç†JSONæ–‡ä»¶çš„è¾“å‡ºå’Œå¢é‡æ›´æ–°"""
    
    def __init__(self, base_dir: Optional[Path] = None):
        """
        åˆå§‹åŒ–è¾“å‡ºç®¡ç†å™¨
        
        Args:
            base_dir: åŸºç¡€è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä¸ºé¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ output/
        """
        if base_dir is None:
            # é»˜è®¤ä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ output/
            base_dir = Path(__file__).parent.parent.parent / "output"
        
        self.base_dir = Path(base_dir)
        self._ensure_directories()
    
    def _ensure_directories(self) -> None:
        """ç¡®ä¿æ‰€æœ‰å¿…è¦çš„ç›®å½•å­˜åœ¨"""
        # åªç¡®ä¿dailyç›®å½•å­˜åœ¨
        self.base_dir.mkdir(parents=True, exist_ok=True)
        self.get_daily_dir().mkdir(parents=True, exist_ok=True)
    
    def get_daily_dir(self, date: Optional[datetime] = None) -> Path:
        """
        è·å–æŒ‰æ—¥æœŸç»„ç»‡çš„ç›®å½•è·¯å¾„
        
        Args:
            date: æ—¥æœŸå¯¹è±¡ï¼Œé»˜è®¤ä¸ºä»Šå¤©
            
        Returns:
            æ—¥æœŸç›®å½•è·¯å¾„ï¼Œæ ¼å¼: output/daily/YYYY-MM-DD/
        """
        if date is None:
            date = datetime.now()
        
        date_str = date.strftime("%Y-%m-%d")
        return self.base_dir / "daily" / date_str
    
    
    def save_result(
        self,
        result: Union[FetchResult, SearchResult],
        filename: Optional[str] = None
    ) -> Path:
        """
        ä¿å­˜æŠ“å–ç»“æœåˆ°æ–‡ä»¶ï¼ˆä»…ä¿å­˜åˆ°dailyç›®å½•ï¼‰
        
        Args:
            result: æŠ“å–ç»“æœå¯¹è±¡
            filename: è‡ªå®šä¹‰æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰ï¼Œé»˜è®¤ä½¿ç”¨æ—¶é—´æˆ³
            
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        # ç”Ÿæˆæ–‡ä»¶å
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            if isinstance(result, FetchResult):
                source_type = result.source_type
                filename = f"{source_type}_{timestamp}"
            else:
                filename = f"search_{timestamp}"
        
        # å‡†å¤‡JSONæ•°æ®
        json_data = result.model_dump(mode='json', exclude_none=True)
        
        # ä¿å­˜åˆ°æ—¥æœŸç›®å½•
        daily_dir = self.get_daily_dir()
        daily_dir.mkdir(parents=True, exist_ok=True)
        daily_file = daily_dir / f"{filename}.json"
        self._write_json(daily_file, json_data)
        
        # å¯é€‰ï¼šè‡ªåŠ¨åŒæ­¥åˆ°Notion
        self._auto_sync_to_notion(result)
        
        return daily_file
    
    def save_incremental(
        self,
        result: FetchResult,
        append: bool = True
    ) -> Path:
        """
        å¢é‡ä¿å­˜ç»“æœï¼ˆè¿½åŠ åˆ°å½“å¤©çš„æ±‡æ€»æ–‡ä»¶ï¼‰
        
        Args:
            result: æŠ“å–ç»“æœå¯¹è±¡
            append: æ˜¯å¦è¿½åŠ åˆ°ç°æœ‰æ–‡ä»¶ï¼ŒFalseåˆ™åˆ›å»ºæ–°æ–‡ä»¶
            
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        daily_dir = self.get_daily_dir()
        daily_dir.mkdir(parents=True, exist_ok=True)
        
        # æ–‡ä»¶åæ ¼å¼: {source_type}_YYYY-MM-DD.json
        date_str = datetime.now().strftime("%Y-%m-%d")
        filename = f"{result.source_type}_{date_str}.json"
        file_path = daily_dir / filename
        
        # è¯»å–ç°æœ‰æ•°æ®æˆ–åˆ›å»ºæ–°ç»“æ„
        if append and file_path.exists():
            with open(file_path, 'r', encoding='utf-8') as f:
                existing_data = json.load(f)
            
            # è¿½åŠ æ–°ç»“æœ
            if isinstance(existing_data, list):
                existing_data.append(result.model_dump(mode='json', exclude_none=True))
            else:
                # å¦‚æœç°æœ‰æ•°æ®æ˜¯å•ä¸ªå¯¹è±¡ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨
                existing_data = [existing_data, result.model_dump(mode='json', exclude_none=True)]
        else:
            # åˆ›å»ºæ–°æ–‡ä»¶ï¼Œä½¿ç”¨åˆ—è¡¨æ ¼å¼
            existing_data = [result.model_dump(mode='json', exclude_none=True)]
        
        # å†™å…¥æ–‡ä»¶
        self._write_json(file_path, existing_data)
        
        # å¯é€‰ï¼šè‡ªåŠ¨åŒæ­¥åˆ°Notion
        if isinstance(result, FetchResult):
            self._auto_sync_to_notion(result)
        
        return file_path
    
    def append_items_batch(
        self,
        source_type: str,
        items: list,
        batch_info: Optional[dict] = None
    ) -> Path:
        """
        æ‰¹é‡è¿½åŠ itemsåˆ°å½“å¤©æ–‡ä»¶ï¼ˆç”¨äºå¢é‡è¾“å‡ºï¼‰
        
        é€‚ç”¨åœºæ™¯ï¼šAIç­›é€‰ååˆ†æ‰¹ç¿»è¯‘+ä¿å­˜ï¼Œé¿å…ä¸€æ¬¡æ€§å¤„ç†å¯¼è‡´ä¸­é€”å¼‚å¸¸ä¸¢å¤±æ‰€æœ‰æ•°æ®
        
        Args:
            source_type: æ•°æ®æºç±»å‹ (hackernews, github, etc.)
            items: ArticleItemåˆ—è¡¨
            batch_info: æ‰¹æ¬¡ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰ï¼Œå¦‚ {"batch": 1, "total_batches": 10}
            
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        daily_dir = self.get_daily_dir()
        daily_dir.mkdir(parents=True, exist_ok=True)
        
        # æŸ¥æ‰¾å½“å¤©æ˜¯å¦å·²æœ‰è¯¥sourceçš„æ–‡ä»¶ï¼ˆåŒä¸€æ¬¡æ‰§è¡Œå‘¨æœŸå†…è¿½åŠ åˆ°åŒä¸€ä¸ªæ–‡ä»¶ï¼‰
        existing_files = list(daily_dir.glob(f"{source_type}_*.json"))
        
        # å¦‚æœå­˜åœ¨å½“å¤©çš„æ–‡ä»¶ï¼Œä½¿ç”¨æœ€æ–°çš„ä¸€ä¸ªï¼ˆæŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼‰
        if existing_files:
            existing_files.sort(key=lambda p: p.stat().st_mtime, reverse=True)
            file_path = existing_files[0]
        else:
            # å¦‚æœä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°æ–‡ä»¶
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"{source_type}_{timestamp}.json"
            file_path = daily_dir / filename
        
        # è¯»å–ç°æœ‰æ•°æ®æˆ–åˆ›å»ºæ–°ç»“æ„
        if file_path.exists():
            with open(file_path, 'r', encoding='utf-8') as f:
                existing_data = json.load(f)
        else:
            # åˆ›å»ºæ–°æ–‡ä»¶ç»“æ„
            existing_data = {
                "success": True,
                "source_name": source_type.title(),
                "source_type": source_type,
                "fetched_at": datetime.now().isoformat(),
                "total_count": 0,
                "items": [],
                "batch_info": batch_info or {}
            }
        
        # è¿½åŠ items
        for item in items:
            if hasattr(item, 'model_dump'):
                existing_data["items"].append(item.model_dump(mode='json', exclude_none=True))
            elif isinstance(item, dict):
                existing_data["items"].append(item)
        
        # æ›´æ–°è®¡æ•°
        existing_data["total_count"] = len(existing_data["items"])
        
        # æ›´æ–°æ‰¹æ¬¡ä¿¡æ¯
        if batch_info:
            existing_data["batch_info"] = batch_info
        
        # å†™å…¥æ–‡ä»¶
        self._write_json(file_path, existing_data)
        
        # å¯é€‰ï¼šè‡ªåŠ¨åŒæ­¥åˆ°Notionï¼ˆä»…åŒæ­¥æ–°å¢çš„itemsï¼‰
        if items:
            from ..models import FetchResult
            temp_result = FetchResult(
                success=True,
                source_name=source_type.title(),
                source_type=source_type,
                total_count=len(items),
                fetched_at=datetime.now().isoformat(),
                items=items
            )
            self._auto_sync_to_notion(temp_result)
        
        return file_path
    
    def _auto_sync_to_notion(self, result: Union[FetchResult, 'SearchResult']) -> None:
        """
        è‡ªåŠ¨åŒæ­¥åˆ°Notionï¼ˆå¦‚æœé…ç½®å¯ç”¨ï¼‰
        
        Args:
            result: FetchResultæˆ–SearchResultå¯¹è±¡
        """
        try:
            from ..utils.notion_sync import get_notion_sync
            
            notion_sync = get_notion_sync()
            if not notion_sync or not notion_sync.enabled:
                return
            
            # åªåŒæ­¥FetchResult
            if isinstance(result, FetchResult) and result.items:
                sync_result = notion_sync.sync_fetch_result(result, skip_existing=True)
                if sync_result.get("success"):
                    synced = sync_result.get("synced", 0)
                    if synced > 0:
                        logger.info(f"ğŸ“ è‡ªåŠ¨åŒæ­¥åˆ°Notion: {synced} æ¡æ–°å†…å®¹")
        except Exception as e:
            # é™é»˜å¤±è´¥ï¼Œä¸å½±å“ä¸»æµç¨‹
            logger.debug(f"Notionè‡ªåŠ¨åŒæ­¥å¤±è´¥: {e}")
    
    def get_daily_summary(self, date: Optional[datetime] = None) -> dict:
        """
        è·å–æŒ‡å®šæ—¥æœŸçš„æ±‡æ€»ä¿¡æ¯
        
        Args:
            date: æ—¥æœŸå¯¹è±¡ï¼Œé»˜è®¤ä¸ºä»Šå¤©
            
        Returns:
            æ±‡æ€»ä¿¡æ¯å­—å…¸
        """
        daily_dir = self.get_daily_dir(date)
        
        if not daily_dir.exists():
            return {
                "date": date.strftime("%Y-%m-%d") if date else datetime.now().strftime("%Y-%m-%d"),
                "files": [],
                "total_files": 0
            }
        
        files = list(daily_dir.glob("*.json"))
        return {
            "date": date.strftime("%Y-%m-%d") if date else datetime.now().strftime("%Y-%m-%d"),
            "files": [f.name for f in files],
            "total_files": len(files),
            "file_paths": [str(f) for f in files]
        }
    
    def _write_json(self, file_path: Path, data: Union[dict, list]) -> None:
        """
        å†™å…¥JSONæ–‡ä»¶
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            data: è¦å†™å…¥çš„æ•°æ®
        """
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    
    def get_output_structure(self) -> dict[str, str]:
        """
        è·å–è¾“å‡ºç›®å½•ç»“æ„ä¿¡æ¯
        
        Returns:
            ç›®å½•ç»“æ„å­—å…¸
        """
        return {
            "base": str(self.base_dir),
            "daily": str(self.get_daily_dir())
        }


# å…¨å±€è¾“å‡ºç®¡ç†å™¨å®ä¾‹
_output_manager: Optional[OutputManager] = None


def get_output_manager(base_dir: Optional[Path] = None) -> OutputManager:
    """
    è·å–å…¨å±€è¾“å‡ºç®¡ç†å™¨å®ä¾‹
    
    Args:
        base_dir: åŸºç¡€è¾“å‡ºç›®å½•
        
    Returns:
        è¾“å‡ºç®¡ç†å™¨å®ä¾‹
    """
    global _output_manager
    if _output_manager is None:
        _output_manager = OutputManager(base_dir)
    return _output_manager


def reset_output_manager() -> None:
    """é‡ç½®å…¨å±€è¾“å‡ºç®¡ç†å™¨ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
    global _output_manager
    _output_manager = None
